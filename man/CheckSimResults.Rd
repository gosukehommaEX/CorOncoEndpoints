% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/CheckSimResults.R
\name{CheckSimResults}
\alias{CheckSimResults}
\title{Check Simulation Results Against Theoretical Values}
\usage{
CheckSimResults(
  dataset,
  p = NULL,
  hazard_OS = NULL,
  hazard_PFS = NULL,
  rho_tte_resp = NULL,
  copula = NULL
)
}
\arguments{
\item{dataset}{A data frame. The output from \code{\link{rOncoEndpoints}}
containing simulated endpoint data with columns simID, Group, and endpoint
variables (OS, PFS, and/or Response).}

\item{p}{Named numeric vector or NULL. The true probabilities of the binary
response endpoint for each group. Names must match group names in dataset.
Required if Response endpoint is present. Example: c(Treatment = 0.4, Control = 0.3)}

\item{hazard_OS}{Named numeric vector or NULL. The hazard rates for OS for
each group. Names must match group names in dataset. Required if OS
endpoint is present. Example: c(Treatment = 0.05, Control = 0.07)}

\item{hazard_PFS}{Named numeric vector or NULL. The hazard rates for PFS for
each group. Names must match group names in dataset. Required if PFS
endpoint is present. Example: c(Treatment = 0.08, Control = 0.10)}

\item{rho_tte_resp}{Named numeric vector or NULL. The specified correlations
between TTE and Response for each group. Names must match group names in
dataset. Required if both TTE and Response endpoints are present.
Example: c(Treatment = 0.3, Control = 0.2)}

\item{copula}{Character or NULL. The copula family used for modeling dependence.
Options are "Clayton" or "Frank". Required if both TTE and Response
endpoints are present.}
}
\value{
A tibble with the following columns:
\describe{
\item{Group}{Treatment group name}
\item{Endpoint}{Name of the endpoint or statistic}
\item{Empirical}{Mean of estimates across simulations}
\item{Theoretical}{Expected theoretical value}
\item{Bias}{Bias = Empirical - Theoretical (signed difference showing
direction of systematic error)}
\item{Relative_Bias}{Relative bias as percentage: 100 × Bias / Theoretical.
Positive values indicate overestimation, negative values indicate
underestimation}
\item{SE}{Empirical standard error (SD of estimates across simulations)}
\item{MSE}{Mean squared error = Bias² + SE²}
\item{RMSE}{Root mean squared error = √MSE (overall accuracy in original scale)}
\item{Assessment}{Quick interpretation: "Excellent" (|Relative_Bias| < 5\%),
"Acceptable" (5\% ≤ |Relative_Bias| < 10\%), "Review" (|Relative_Bias| ≥ 10\%)}
}
}
\description{
Compares empirical simulation results from \code{\link{rOncoEndpoints}} with
their corresponding theoretical values. This function calculates standard
performance metrics (Bias, Relative Bias, SE, MSE, RMSE) for validating
simulation implementations and assessing the accuracy of the proposed
random number generation method.
}
\details{
This function calculates both empirical and theoretical values for:

\strong{Time-to-event endpoints (OS/PFS):}
\itemize{
\item Mean: Empirical vs 1/hazard
\item Median: Empirical vs log(2)/hazard
}

\strong{Binary endpoint (Response):}
\itemize{
\item Proportion: Empirical vs p
}

\strong{Correlations:}
\itemize{
\item Corr(OS, Response): Empirical vs rho_tte_resp (specified)
\item Corr(PFS, Response): Empirical vs value calculated by \code{\link{CorResponsePFS}}
\item Corr(OS, PFS): Empirical vs hazard_OS / hazard_PFS (Fleischer model)
}

\strong{Performance metrics:}
\itemize{
\item \strong{Bias}: Measures systematic error. Should be close to 0 for unbiased
methods. Sign indicates direction: positive = overestimation,
negative = underestimation
\item \strong{Relative Bias (\%)}: Bias relative to true value. Recommended
interpretation: <5\% excellent, <10\% acceptable
\item \strong{SE (Standard Error)}: Measures variability of estimates. Decreases
with √nsim. Smaller is better
\item \strong{MSE}: Combines bias and variance into single metric. Smaller is better
\item \strong{RMSE}: MSE in original scale. Directly comparable to SE
\item \strong{Assessment}: Automatic interpretation based on relative bias
}

The function is particularly useful for:
\itemize{
\item Validating that \code{\link{rOncoEndpoints}} correctly implements the models
\item Demonstrating unbiasedness of the proposed method for publication
\item Checking if sufficient simulations have been run (SE should be small)
\item Understanding the relationship between parameters and resulting correlations
\item Quality control in simulation studies
}
}
\note{
\strong{Interpretation guidelines:}
\itemize{
\item \strong{Bias close to 0}: Method is unbiased (desirable for publication)
\item \strong{Relative Bias < 5\%}: Excellent performance
\item \strong{Relative Bias < 10\%}: Acceptable performance
\item \strong{Small SE}: Stable estimates (increase nsim to reduce SE)
\item \strong{RMSE ≈ SE when Bias ≈ 0}: Indicates unbiased estimator
\item \strong{Correlations typically show higher variability} (larger SE/RMSE)
than means/medians, especially with smaller sample sizes
}

\strong{For publication:}
\itemize{
\item Report Bias and Relative Bias to demonstrate unbiasedness
\item Report SE to show precision
\item Report MSE or RMSE for overall accuracy
\item Typical table format: Group | Endpoint | Theoretical | Empirical |
Bias | Relative Bias (\%) | SE | RMSE | Assessment
}
}
\examples{
# Example 1: OS and Response with Clayton copula
set.seed(123)
sim_data1 <- rOncoEndpoints(
  nsim = 1000,
  group = c("Treatment", "Control"),
  n = c(100, 100),
  p = c(0.4, 0.3),
  hazard_OS = c(0.05, 0.07),
  rho_tte_resp = c(0.3, 0.2),
  copula = "Clayton"
)

check1 <- CheckSimResults(
  dataset = sim_data1,
  p = c(Treatment = 0.4, Control = 0.3),
  hazard_OS = c(Treatment = 0.05, Control = 0.07),
  rho_tte_resp = c(Treatment = 0.3, Control = 0.2),
  copula = "Clayton"
)
print(check1, n = Inf)

# Interpretation:
# - Bias close to 0: method is unbiased
# - Relative_Bias < 5\%: excellent performance
# - Small SE: precise estimates
# - RMSE ≈ SE when Bias ≈ 0: confirms unbiasedness

# Example 2: All three endpoints (OS, PFS, Response) with Frank copula
set.seed(456)
sim_data2 <- rOncoEndpoints(
  nsim = 1000,
  group = c("Experimental", "Standard"),
  n = c(150, 150),
  p = c(0.5, 0.35),
  hazard_OS = c(0.04, 0.06),
  hazard_PFS = c(0.08, 0.10),
  rho_tte_resp = c(0.4, 0.25),
  copula = "Frank"
)

check2 <- CheckSimResults(
  dataset = sim_data2,
  p = c(Experimental = 0.5, Standard = 0.35),
  hazard_OS = c(Experimental = 0.04, Standard = 0.06),
  hazard_PFS = c(Experimental = 0.08, Standard = 0.10),
  rho_tte_resp = c(Experimental = 0.4, Standard = 0.25),
  copula = "Frank"
)
print(check2, n = Inf)

# Note: PFS-Response correlation theoretical values are calculated
# using CorResponsePFS function, demonstrating the consistency
# of the three-endpoint model

}
\references{
Fleischer, F., Gaschler-Markefski, B., & Bluhmki, E. (2009). A statistical
model for the dependence between progression-free survival and overall
survival. Statistics in Medicine, 28(21), 2669-2686.
}
\seealso{
\code{\link{rOncoEndpoints}} for generating correlated oncology endpoints,
\code{\link{CorResponsePFS}} for calculating PFS-Response correlation,
\code{\link{CorBoundResponseTTE}} for correlation bounds,
\code{\link{CopulaParamResponseTTE}} for copula parameters
}
